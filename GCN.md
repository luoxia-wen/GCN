# GCN基本数学原理

## 1.基本思路

​	考虑下图中绿色节点。首先，我们得到它的所有邻居的特征值，包括自身节点，接着取平均值。最后通过神经网络返回一个结果向量并将此作为最终结果：

![img](https://img-blog.csdnimg.cn/img_convert/3c9a7f4c562a369397b750de033566f9.png)



## 2.基本情景

​	对于图G，可以得到其邻接矩阵A、度矩阵D还有输入特征X，如下：

![img](https://img-blog.csdnimg.cn/img_convert/9f06f5447f13b8f1923204400bd7af90.png)

## 3.计算过程

### 3.1基本计算过程

​	得到每一个节点的特征的关键之处在于A和X的相乘。

​	看看邻接矩阵的第一行，我们看到节点A与节点E之间有连接，得到的矩阵第一行就是与A相连接的E节点的特征向量（如下图）。同理，得到的矩阵的第二行是D和E的特征向量之和，通过这个方法，我们可以得到所有邻居节点的向量之和。

![img](https://img-blog.csdnimg.cn/img_convert/9d2dc5f9274eea7bde6158a45e85cd62.png)

​	



> ==计算过程中存在一些问题：==
>
> 1. 我们忽略了节点本身的特征。例如，计算得到的矩阵的第一行也应该包含节点A的特征。
> 2. 我们不需要使用sum()函数，而是需要取平均值，甚至更好的邻居节点特征向量的加权平均值。那我们为什么不使用sum()函数呢？原因是在使用sum()函数时，度大的节点很可能会生成的大的v向量，而度低的节点往往会得到小的聚集向量，这可能会在以后造成梯度爆炸或梯度消失（例如，使用sigmoid时）。此外，神经网络似乎对输入数据的规模很敏感。因此，我们需要对这些向量进行归一化，以摆脱可能出现的问题。



### 3.2改进

​	对于问题1，可以通过在$A$中增加一个单位矩阵$I$来解决：
$$
\tilde{\mathbf{A}} = \mathbf {A} + \lambda {\mathbf{I_N}}
$$
​	取$\lambda = 1$，（使得节点本身的特征和邻居一样重要），我们就有$\tilde{\mathbf{A}} = \mathbf {A} + \mathbf{I_N}$，注意，我们==可以把$\lambda$当做一个可训练的参数==，但现在只要把$\lambda$赋值为1就可以了，即使在论文中，$\lambda$也只是简单的赋值为1。



​	对于问题2，从问题2的起因可知，该问题与度矩阵$\tilde{D}$有关（$\tilde{A}$的度矩阵）。

* 如果采取平均的方法，那么矩阵$\tilde{D}$的逆矩阵$\tilde{D}^{-1}$即可实现：

![img](https://img-blog.csdnimg.cn/img_convert/bc075e08dedabd3f7ea0ab94d96d430c.png)



​	例如，节点A的度数为2，所以我们将节点A的聚合向量乘以1/2，而节点E的度数为5，我们应该将E的聚合向量乘以1/5，以此类推。

​	因此有：

![img](https://img-blog.csdnimg.cn/img_convert/d8363c95ab404d0e93045da6eb40df2a.png)



* 从直觉上来看，似乎采用加权平均，对高低度的节点区别对待，可以得到更好的结果

![img](https://img-blog.csdnimg.cn/img_convert/418194f8c2ce77304ac4621adff09326.png)

​	

​	给低度的节点加更多的权重，以减少高度节点的影响。这个加权平均的想法是，假设低度节点会对邻居节点产生更大的影响，而高度节点则会产生较低的影响，因为它们的影响力分散在太多的邻居节点上。

![img](https://img-blog.csdnimg.cn/img_convert/3364b36eb2317f54079c959d1f3be765.png)

​	

​	由上图可知，在行和列分别进行了一次正则化（normalize），因此，将度矩阵修改为$\tilde{D}^{-1/2}$，如下：

![img](https://img-blog.csdnimg.cn/img_convert/767450beaa71a7ed3438c775042b05e5.png)

### 3.3小结

* $\tilde{A}X$：包含了节点本身特征的所有邻居特征之和；
* $\tilde{D}^{-1}\tilde{A}X$：包含了节点本身特征的邻居特征之和平均值，在这里邻接矩阵每一行都按度矩阵的逆平衡；
* $\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}X$：包含了节点本身特征的邻居特征之和平均值，在这里邻接矩阵每一行和每一列都按度矩阵的逆（1/2的版本）平衡，从而得到加权平均过的特征值；



